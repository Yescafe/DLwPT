{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5be46f8db0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data/ch7'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                3072,\n",
    "                512,\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(\n",
    "                512,\n",
    "                n_out,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "softmax(x_1, x_2) = (\\frac{e^{x_1}}{e^{x_1} + e^{x_2}},\\frac{e^{x_2}}{e^{x_1} + e^{x_2}}) \\\\\n",
    "softmax(x_1, \\dots, x_n) = (\\frac{e^{x_1}}{e^{x_1} + \\dots + e^{x_n}}, \\dots, \\frac{e^{x_n}}{e^{x_1} + \\dots + e^{x_n}})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\sum softmax(x)=\\sum\\limits_{i=0}^{N}\\frac{e^i}{\\sum_{j=0}^{N} e^j}=1\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[1., 2., 3.],\n",
    "                  [1., 2., 3.]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4784, 0.5216]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5077, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('Epoch: {}, Loss: {}'.format(epoch, float(loss)))\n",
    "    \n",
    "toc = time.time()\n",
    "print('Spend time ' + str(toc - tic) + 's')\n",
    "'''\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5669606924057007\n",
      "Epoch: 2, Loss: 0.3292829394340515\n",
      "Epoch: 3, Loss: 0.49530547857284546\n",
      "Epoch: 4, Loss: 0.35676783323287964\n",
      "Epoch: 5, Loss: 0.19398456811904907\n",
      "Epoch: 6, Loss: 0.46490418910980225\n",
      "Epoch: 7, Loss: 0.45544928312301636\n",
      "Epoch: 8, Loss: 0.46037939190864563\n",
      "Epoch: 9, Loss: 0.24305753409862518\n",
      "Epoch: 10, Loss: 0.43668925762176514\n",
      "Epoch: 11, Loss: 0.349956214427948\n",
      "Epoch: 12, Loss: 0.4603939354419708\n",
      "Epoch: 13, Loss: 0.39098405838012695\n",
      "Epoch: 14, Loss: 0.4621390104293823\n",
      "Epoch: 15, Loss: 0.22492431104183197\n",
      "Epoch: 16, Loss: 0.5685446858406067\n",
      "Epoch: 17, Loss: 0.5020055770874023\n",
      "Epoch: 18, Loss: 0.2851449251174927\n",
      "Epoch: 19, Loss: 0.4238271117210388\n",
      "Epoch: 20, Loss: 0.4577503204345703\n",
      "Epoch: 21, Loss: 0.41526052355766296\n",
      "Epoch: 22, Loss: 0.29702848196029663\n",
      "Epoch: 23, Loss: 0.22636890411376953\n",
      "Epoch: 24, Loss: 0.04349592700600624\n",
      "Epoch: 25, Loss: 0.3086414635181427\n",
      "Epoch: 26, Loss: 0.33681151270866394\n",
      "Epoch: 27, Loss: 0.26489609479904175\n",
      "Epoch: 28, Loss: 0.08091676235198975\n",
      "Epoch: 29, Loss: 0.1901094764471054\n",
      "Epoch: 30, Loss: 0.11398032307624817\n",
      "Epoch: 31, Loss: 0.1395701766014099\n",
      "Epoch: 32, Loss: 0.2436112016439438\n",
      "Epoch: 33, Loss: 0.16624850034713745\n",
      "Epoch: 34, Loss: 0.2901706397533417\n",
      "Epoch: 35, Loss: 0.12984786927700043\n",
      "Epoch: 36, Loss: 0.22086738049983978\n",
      "Epoch: 37, Loss: 0.18389548361301422\n",
      "Epoch: 38, Loss: 0.1471828669309616\n",
      "Epoch: 39, Loss: 0.0658193975687027\n",
      "Epoch: 40, Loss: 0.16718946397304535\n",
      "Epoch: 41, Loss: 0.10895363986492157\n",
      "Epoch: 42, Loss: 0.1014706939458847\n",
      "Epoch: 43, Loss: 0.17072156071662903\n",
      "Epoch: 44, Loss: 0.19477859139442444\n",
      "Epoch: 45, Loss: 0.10118971765041351\n",
      "Epoch: 46, Loss: 0.07290047407150269\n",
      "Epoch: 47, Loss: 0.0800400972366333\n",
      "Epoch: 48, Loss: 0.049822013825178146\n",
      "Epoch: 49, Loss: 0.1285448670387268\n",
      "Epoch: 50, Loss: 0.0572759211063385\n",
      "Epoch: 51, Loss: 0.061926309019327164\n",
      "Epoch: 52, Loss: 0.13184332847595215\n",
      "Epoch: 53, Loss: 0.07793376594781876\n",
      "Epoch: 54, Loss: 0.05848990008234978\n",
      "Epoch: 55, Loss: 0.033857185393571854\n",
      "Epoch: 56, Loss: 0.14310579001903534\n",
      "Epoch: 57, Loss: 0.07796145230531693\n",
      "Epoch: 58, Loss: 0.03718651458621025\n",
      "Epoch: 59, Loss: 0.04514247179031372\n",
      "Epoch: 60, Loss: 0.0521017350256443\n",
      "Epoch: 61, Loss: 0.045771874487400055\n",
      "Epoch: 62, Loss: 0.04536500573158264\n",
      "Epoch: 63, Loss: 0.09326392412185669\n",
      "Epoch: 64, Loss: 0.05960790812969208\n",
      "Epoch: 65, Loss: 0.03100479394197464\n",
      "Epoch: 66, Loss: 0.05012236908078194\n",
      "Epoch: 67, Loss: 0.06405744701623917\n",
      "Epoch: 68, Loss: 0.019320815801620483\n",
      "Epoch: 69, Loss: 0.023396557196974754\n",
      "Epoch: 70, Loss: 0.05266650393605232\n",
      "Epoch: 71, Loss: 0.05670236051082611\n",
      "Epoch: 72, Loss: 0.05003298819065094\n",
      "Epoch: 73, Loss: 0.006813135929405689\n",
      "Epoch: 74, Loss: 0.024147534742951393\n",
      "Epoch: 75, Loss: 0.022083327174186707\n",
      "Epoch: 76, Loss: 0.019744448363780975\n",
      "Epoch: 77, Loss: 0.012790205888450146\n",
      "Epoch: 78, Loss: 0.0064744665287435055\n",
      "Epoch: 79, Loss: 0.05186357721686363\n",
      "Epoch: 80, Loss: 0.019758306443691254\n",
      "Epoch: 81, Loss: 0.07990676164627075\n",
      "Epoch: 82, Loss: 0.019360879436135292\n",
      "Epoch: 83, Loss: 0.02527010440826416\n",
      "Epoch: 84, Loss: 0.026254398748278618\n",
      "Epoch: 85, Loss: 0.04338978976011276\n",
      "Epoch: 86, Loss: 0.004478744231164455\n",
      "Epoch: 87, Loss: 0.005016452167183161\n",
      "Epoch: 88, Loss: 0.009721399284899235\n",
      "Epoch: 89, Loss: 0.02365083433687687\n",
      "Epoch: 90, Loss: 0.012609305791556835\n",
      "Epoch: 91, Loss: 0.035370148718357086\n",
      "Epoch: 92, Loss: 0.01558475848287344\n",
      "Epoch: 93, Loss: 0.010696056298911572\n",
      "Epoch: 94, Loss: 0.0349452868103981\n",
      "Epoch: 95, Loss: 0.02359236776828766\n",
      "Epoch: 96, Loss: 0.013416353613138199\n",
      "Epoch: 97, Loss: 0.013688325881958008\n",
      "Epoch: 98, Loss: 0.011478268541395664\n",
      "Epoch: 99, Loss: 0.04225252941250801\n",
      "Epoch: 100, Loss: 0.006068466231226921\n",
      "Spend time 0h3m20s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "tic = time.time()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch: {}, Loss: {}'.format(epoch+1, float(loss)))\n",
    "    \n",
    "toc = time.time()\n",
    "delta_time = toc - tic\n",
    "print('Spend time ' + str(int(delta_time / 3600)) + 'h' + \n",
    "      str(int(delta_time / 60 % 60)) + 'm' + str(int(delta_time % 60)) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "    \n",
    "print('Accuracy: {}'.format(correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()  # combination of nn.LogSoftmax and nn.NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "p.numel() = (N_{weight}\\times N_{bias}, N_{bias})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574402, [1572864, 512, 1024, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                3072,\n",
    "                512,\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(\n",
    "                512,\n",
    "                n_out,\n",
    "            )\n",
    "        )\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "mes",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
